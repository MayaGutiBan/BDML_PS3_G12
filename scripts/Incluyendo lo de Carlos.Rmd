---
title: "Soluci√≥n Taller No. 3"
author: "Sebasti√°n"
date: "2025-05-20"
output: html_document
---

```{r}
if(!require(pacman)) install.packages("pacman") ; require(pacman)
if(!require(janitor)) install.packages("janitor") ; require(janitor)
if(!require(readxl)) install.packages("readxl") ; require(readxl)
if(!require(writexl)) install.packages("writexl") ; require(writexl)
if(!require(sf)) install.packages("sf") ; require(sf)
if(!require(geojsonio)) install.packages("geojsonio") ; require(geojsonio)
if(!require(GGally)) install.packages("GGally") ; require(GGally)
if(!require(leaflet)) install.packages("leaflet") ; require(leaflet)
if(!require(VIM)) install.packages("VIM") ; require(VIM)
if(!require(stringr)) install.packages("stringr") ; require(stringr)
if(!require(readr)) install.packages("readr") ; require(readr)
if(!require(osmdata)) install.packages("osmdata") ; require(osmdata)

if(!require(jsonlite)) install.packages("jsonlite") ; require(jsonlite) #No
if(!require(rvest)) install.packages("rvest") ; require(rvest) #No
if(!require(httr)) install.packages("httr") ; require(httr) #No

p_load(rio, # import/export data
       tidyverse, # Manipular dataframes
       glmnet, # To implement regularization algorithms. 
       caret, # Creating predictive models
       scatterplot3d, # For 3D visualization
       plotly, # For interactive 3D plots
       skimr, #sumary data
       gridExtra, #visualizaing missing data
       corrplot, #correlation PLots
       stargazer, #tables/outpot to TEX
       MASS, #Various statistcal functions
       readxl,
       readr,
       writexl,
       stringi, #Manipular cadenas de texto
       tm,  # Para text mining
       tidytext,  #Para tokenizaci√≥n
       stopwords,  #consultar stopwords
       tidymodels, #modelos de machine learning
       sf, # leer/escribir/manipular datos espaciales
       spatialsample,  #Validaci√≥n cruzada espacial
       janitor, 
       leaflet, # Mapas interactivos
       VIM,  # Imputar por Vercino m√°s cercano (KNN)
       ggcorrplot,
       janitor,
       jsonlite,
       httr,
       plotly, # Gr√°ficos interactivos
)
```


# -----------------------------------------------------------------------------------------------------------------------------
# 1. Cargando base de datos
# -----------------------------------------------------------------------------------------------------------------------------
```{r}
library(readr)

test <- read.csv("https://raw.githubusercontent.com/Jusebastru/Probelm_Set_3/refs/heads/main/test.csv", 
                 sep = ",", 
                 stringsAsFactors = TRUE)

train <- read.csv("https://raw.githubusercontent.com/Jusebastru/Probelm_Set_3/refs/heads/main/train.csv", 
                  sep = ",", 
                  stringsAsFactors = TRUE)

sumission <- read.csv("https://raw.githubusercontent.com/Jusebastru/Probelm_Set_3/refs/heads/main/submission_template.csv", 
                      sep = ",", 
                      stringsAsFactors = TRUE)

#####################  6.2.1. Se descarga dede https://github.com/Jusebastru/Probelm_Set_3/blob/main/upz-bogota.xlsx 

upz_bogota <- st_read("C:/Users/Juancho/OneDrive/Desktop/MeCA/Big Data y Maching Learning/Taller No. 3./upz-bogota.geojson",
                      quiet = TRUE)

```

Inicialmente, cargamos las bases de datos del Problem Set No. 3. Incluimos una cuarta base de datos, las Unidades de Planeamiento Zonal (UPZ) de Bogot√° D.C. Las UPZ se pueden definir como territorios que concentran algunos barrios dentro de las localidades y permiten planificar el desarrollo urbano a un nivel zonal. Para nuestro ejercicio, se descarg√≥ el formato .Geojson de la p√°gina web: https://bogota-laburbano.opendatasoft.com/explore/dataset/upz-bogota/export/, la cual se carg√≥ al repositorio Github.

# -----------------------------------------------------------------------------------------------------------------------------
# 2. Funci√≥n para variables decriptivas
# -----------------------------------------------------------------------------------------------------------------------------
```{r}

###########################################    2.1 Pasar de texto a datos 

limpiar_y_enriquecer <- function(df) {
  df <- df %>%
    # Limpieza del texto
    mutate(description = str_to_lower(description)) %>%
    mutate(description = stringi::stri_trans_general(description, "Latin-ASCII")) %>%
    mutate(description = str_replace_all(description, "[^[:alnum:]]", " ")) %>%
    mutate(description = str_trim(gsub("\\s+", " ", description))) %>%
    
    # Inferencia del tipo de propiedad
    mutate(property_type_2 = ifelse(grepl("casa", description), "Casa", property_type)) %>%
    mutate(property_type_2 = ifelse(grepl("apto|apartamento", description), "Apartamento", property_type_2)) %>%
    
    # Extracci√≥n de n√∫mero de alcobas
    mutate(
      alcoba_raw = str_extract(description, "\\d+\\s*(alcobas?|cuartos?|habitaciones?)"),
      alcobas = str_extract(alcoba_raw, "\\d+") %>% as.integer(),
      bedrooms = if_else(is.na(bedrooms), alcobas, bedrooms)
    ) %>%
    
    # Extracci√≥n de si tiene terraza
    mutate(
      tiene_terraza = if_else(str_detect(description, regex("terraza", ignore_case = TRUE)), 1, 0)
    ) %>%
    
    # Extracci√≥n de n√∫mero de ba√±os
    mutate(
      ba√±o_raw = str_extract(description, "\\d+\\s*(ba√±os?|ba√±o|banos|bano)"),
      ba√±os = str_extract(ba√±o_raw, "\\d+") %>% as.integer(),
      bathrooms = if_else(is.na(bathrooms), ba√±os, bathrooms)
    ) %>%
    
    # Extracci√≥n de √°rea construida y asignaci√≥n a surface
    mutate(
      area_matches = str_extract_all(description,  "\\d+\\s*(sal√≥n?|saln|salon)"),
      area_nums = map(area_matches, ~ {
        nums <- str_extract_all(.x, "\\d{1,4}") %>% unlist() %>% as.integer()
        nums[!is.na(nums) & nums >= 20 & nums <= 1000]
      }),
      area_construida = map_int(area_nums, ~ if(length(.x) > 0) max(.x) else NA_integer_),
      surface_covered = if_else(is.na(surface_covered), area_construida, surface_covered),
      surface_total = if_else(is.na(surface_total), area_construida, surface_total)
    ) %>%
    
    # Extracci√≥n de metros de terraza
    mutate(
      terraza_raw = str_extract(description, "(de\\s+)?terraza|patio|balcon\\s+\\d+\\s*(m2|mts|metros)?"),
      m2_terraza = str_extract(terraza_raw, "\\d+") %>% as.integer()
    ) %>%
    
    # Ajuste final de surface_total si a√∫n est√° NA
    mutate(
      surface_total = if_else(
        is.na(surface_total) & !is.na(surface_covered),
        surface_covered + coalesce(m2_terraza, 0),
        surface_total
      )
    ) %>%
    
    # Eliminaci√≥n de columnas auxiliares
    dplyr::select(-alcoba_raw, -alcobas, -ba√±o_raw, -ba√±os, -area_construida, -terraza_raw, -m2_terraza)
  
  return(df)
}

train <- limpiar_y_enriquecer(train)
test <- limpiar_y_enriquecer(test)
```

###### 2.1. Visualizando valores

De las base "test" podemos observar que est√° compuestas por 10286 observaciones (filas) con 20 variables. Aplicando el argumento glimpse(), adem√°s de visualizar la tipolog√≠a de cada variable, se observa que las variables "price", "surface_total", "surface_covered", "bathrooms" y "rooms" contienen missing_values. Para verificar la cantidad de missing_values aplicamos el argumento skim(), donde podemos observar que la variable "price" no aparece precisamente porque su tipolog√≠a es de car√°cter <lgl>, es decir, es una variable que contiene datos de tipo l√≥gico/booleanos que se emplean para representar condiciones, resultados de comparaciones, o cualquier situaci√≥n que requiera una respuesta de s√≠/no o verdadero/falso. En cuanto las dem√°s variables con missing_values, podemos ver que "surface_covered" es la m√°s cr√≠tica, pues  le hacen falta el 72% de las observaciones, seguida con el 66% de "surface_total", 45% de "rooms" y 16% de "bathrooms".

```{r}
glimpse(test)
skimr::skim(test)
visdat::vis_dat(test)
visdat::vis_miss(test)
```

De la base "train" podemos observar que est√° compuesta por 38644 observaciones con 20 variables. Aplicando el argumento glimpse(), se observa que las variables "surface_total", "surface_covered", "rooms" y "bathrooms" cuentan missing_values. A diferencia de la base "test", en "trains" la variable "price" es de tipo doble precisi√≥n, es decir, valores num√©ricos con decimales. Con el argumento skim(), observamos que nuevamente la variable "surface_covered" contiene la mayor cantidad de missing_values, seguido por "surface_total". La variable "bathrooms" contiene la menor cantidad de missing_values. 

Apesar de emplear una estrategia de extracci√≥n de informaci√≥n en "desripcion", sigue habiendo una gran cantidad de missing_values. Por ende, se hace necesario en pensar un mecanismo que permita imputar estos valores lo m√°s pr√≥ximo (preciso) posible. 

```{r}
glimpse(train)
skimr::skim(train)
visdat::vis_dat(train)
```

# ----------------------------------------------------------------------------------------------------------------------------
# 3. Funci√≥n para variables espaciales
# ----------------------------------------------------------------------------------------------------------------------------

Con la finalidad de lograr obtener un buen modelo, se incluyen variables de distancia a restaurantes, hospitales, parques, CAI's de polic√≠a, estaciones de transmilenio. En lo cotidiano, cuando se piensa en arrendar o comprar un inmueble, se piensa en la proximidad este tipo de lugares por salud, entretenimiento, seguridad y movilidad. En cuanto mejor est√© ubicado el inmueble a estos lugares, se podr√≠a intu√≠r que m√°s alto ser√° el precio de venta, compra u/o arriendo.

```{r}

###########################################    3.1 Restaurantes, Hospitales y Parques

# SOLUCI√ìN 1: Reinstalar el paquete curl
install.packages("curl", dependencies = TRUE)

# SOLUCI√ìN 2: Actualizar todos los paquetes involucrados
install.packages(c("curl", "osmdata", "sf", "dplyr"), dependencies = TRUE)

# SOLUCI√ìN 3: Funci√≥n corregida con manejo de errores y dependencias expl√≠citas

agregar_vars_espaciales <- function(sf_data, ciudad = "Bogot√° Colombia", Walkingdistance = 700) {
  # Cargar y verificar las bibliotecas necesarias
  required_packages <- c("dplyr", "sf", "osmdata", "curl")
  
  # Verificar e instalar paquetes faltantes
  for(pkg in required_packages) {
    if(!requireNamespace(pkg, quietly = TRUE)) {
      message(paste("Instalando paquete:", pkg))
      install.packages(pkg)
    }
    library(pkg, character.only = TRUE)
  }
  
  # Verificar que sf_data sea un objeto sf
  if(!inherits(sf_data, "sf")) {
    stop("El objeto proporcionado no es de clase sf")
  }
  
  tryCatch({
    message("Usando bbox de: ", ciudad)
    bbox <- osmdata::getbb(ciudad)
    
    # Asegurarse que el bbox es v√°lido
    if(is.null(bbox) || any(is.na(bbox))) {
      stop("No se pudo obtener un bbox v√°lido para la ciudad especificada")
    }
    
    #### Parques ####
    message("Obteniendo datos de parques...")
    parques <- opq(bbox = bbox) %>%
      add_osm_feature(key = "leisure", value = "park")
    
    parques_sf <- osmdata_sf(parques)
    
    # Verificar que se obtuvieron pol√≠gonos de parques
    if(is.null(parques_sf$osm_polygons) || nrow(parques_sf$osm_polygons) == 0) {
      warning("No se encontraron parques en la zona especificada")
      sf_data$distancia_parque <- NA
    } else {
      parques_poligonos <- parques_sf$osm_polygons %>% st_as_sf()
      centroides_parques <- st_centroid(parques_poligonos) %>%
        mutate(x = st_coordinates(.)[, "X"], y = st_coordinates(.)[, "Y"]) %>%
        st_as_sf(coords = c("x", "y"), crs = 4326)
      
      # Distancia a parque m√°s cercano
      dist_matrix <- st_distance(sf_data, centroides_parques)
      sf_data$distancia_parque <- apply(dist_matrix, 1, min)
    }
    
    #### Hospitales ####
    message("Obteniendo datos de hospitales...")
    hospitales <- opq(bbox = bbox) %>%
      add_osm_feature(key = "amenity", value = "hospital")
    
    hospitales_sf <- osmdata_sf(hospitales)
    
    # Verificar que se obtuvieron pol√≠gonos de hospitales
    if(is.null(hospitales_sf$osm_polygons) || nrow(hospitales_sf$osm_polygons) == 0) {
      warning("No se encontraron hospitales en la zona especificada")
      sf_data$distancia_hospital <- NA
    } else {
      hospitales_poligonos <- hospitales_sf$osm_polygons %>% st_as_sf()
      centroides_hosp <- st_centroid(hospitales_poligonos) %>%
        mutate(x = st_coordinates(.)[, "X"], y = st_coordinates(.)[, "Y"]) %>%
        st_as_sf(coords = c("x", "y"), crs = 4326)
      
      dist_matrix_hosp <- st_distance(sf_data, centroides_hosp)
      sf_data$distancia_hospital <- apply(dist_matrix_hosp, 1, min)
    }
    
    #### Restaurantes ####
    message("Obteniendo datos de restaurantes...")
    restaurantes <- opq(bbox = bbox) %>%
      add_osm_feature(key = "amenity", value = "restaurant")
    
    restaurantes_sf <- osmdata_sf(restaurantes)
    
    # Verificar que se obtuvieron datos de restaurantes
    if((is.null(restaurantes_sf$osm_points) || nrow(restaurantes_sf$osm_points) == 0) && 
       (is.null(restaurantes_sf$osm_polygons) || nrow(restaurantes_sf$osm_polygons) == 0)) {
      warning("No se encontraron restaurantes en la zona especificada")
      sf_data$num_restaurantes_700m <- 0
    } else {
      # Unir puntos y centroides de pol√≠gonos
      puntos <- if(!is.null(restaurantes_sf$osm_points)) {
        restaurantes_sf$osm_points %>% dplyr::select(osm_id, geometry)
      } else {
        st_sf(osm_id = character(0), geometry = st_sfc(), crs = 4326)
      }
      
      poligonos <- if(!is.null(restaurantes_sf$osm_polygons)) {
        restaurantes_sf$osm_polygons %>%
          dplyr::select(osm_id, geometry) %>%
          st_centroid()
      } else {
        st_sf(osm_id = character(0), geometry = st_sfc(), crs = 4326)
      }
      
      restaurantes_all <- bind_rows(puntos, poligonos) %>%
        st_transform(4326)
      
      # Restaurantes en radio
      if(nrow(restaurantes_all) > 0) {
        restaurantes_cercanos <- st_is_within_distance(sf_data, restaurantes_all, dist = Walkingdistance)
        sf_data$num_restaurantes_700m <- lengths(restaurantes_cercanos)
      } else {
        sf_data$num_restaurantes_700m <- 0
      }
    }
    
    message("Proceso completado con √©xito")
    return(sf_data)
    
  }, error = function(e) {
    # Manejo espec√≠fico para el error de curl_parse_url
    if(grepl("curl_parse_url", e$message)) {
      message("Error detectado con curl_parse_url. Intentando reinstalar curl...")
      try(detach("package:curl", unload = TRUE), silent = TRUE)
      try(detach("package:osmdata", unload = TRUE), silent = TRUE)
      install.packages("curl", dependencies = TRUE)
      library(curl)
      message("Por favor, intente ejecutar la funci√≥n nuevamente.")
    } else {
      message("Error en la funci√≥n agregar_vars_espaciales: ", e$message)
    }
    # Devolver los datos originales si hay error
    return(sf_data)
  })
}
```

```{r}
###########################################    3.1.1. Aplicar funci√≥n

# Convertir datos de puntos a objeto espacial con CRS compatible
train_sf <- train %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326)  # Sistema WGS84

test_sf <- test %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326)  # Sistema WGS84


train_sf <- agregar_vars_espaciales(train_sf)
test_sf <- agregar_vars_espaciales(test_sf)
```

```{r}

###########################################    3.2. Estaciones TM y CAIs

# Funci√≥n para a√±adir flags de proximidad
add_proximity_flags <- function(properties_sf,
                                tm_geojson = "https://raw.githubusercontent.com/Jusebastru/Probelm_Set_3/refs/heads/main/Estaciones_Troncales_TM.geojson",
                                cai_geojson = "https://datosabiertos.bogota.gov.co/dataset/bcc51101-762b-4e13-9455-f77502c75a0f/resource/202c5810-6880-43f8-b801-df70aaf6d237/download/comandoatencioninmediata.geojson",
                                dist_threshold = 1000) {
  
  # 1. Leer capas
  tm_sf  <- st_read(tm_geojson, quiet = TRUE)
  cai_sf <- st_read(cai_geojson, quiet = TRUE)
  
  # 2. Transformar CRS para que coincida con properties_sf
  tm_sf  <- st_transform(tm_sf,  st_crs(properties_sf))
  cai_sf <- st_transform(cai_sf, st_crs(properties_sf))
  
  # 3. Calcular matriz de distancias
  d_tm  <- st_distance(properties_sf, tm_sf)   # [n_prop x n_tm]
  d_cai <- st_distance(properties_sf, cai_sf)  # [n_prop x n_cai]
  
  # 4. Distancia m√≠nima por vivienda
  min_dist_tm  <- apply(d_tm,  1, min)
  min_dist_cai <- apply(d_cai, 1, min)
  
  # 5. A√±adir columnas l√≥gicas (TRUE si est√° a ‚â§ dist_threshold metros)
  properties_sf %>%
    mutate(
      dist_to_tm  = as.numeric(min_dist_tm),
      near_tm     = dist_to_tm  <= dist_threshold,
      dist_to_cai = as.numeric(min_dist_cai),
      near_cai    = dist_to_cai <= dist_threshold
    )
}
```

```{r}
###########################################    3.2.1 Aplicar funci√≥n 

train_sf <- add_proximity_flags(train_sf)
test_sf <- add_proximity_flags(test_sf)

```

# -----------------------------------------------------------------------------------------------------------------------------
# 4. Uniendo Bases de Datos
# -----------------------------------------------------------------------------------------------------------------------------

####### 4.1. Uniendo Bases de datos
```{r}

##################################### 4.1. Primero identifico cada base con columna de mismo nombre

test_sf$origen <- "test"
train_sf$origen <- "train"

##################################### 4.2. Uniendo Bases de datos Train_sf y test_Sf 

test_sfyS <- inner_join(test_sf, sumission, by = "property_id")
Base <- bind_rows(test_sfyS, train_sf)

visdat::vis_miss(Base, warn_large_data = FALSE)

#################################### 4.3. Creando Columna PrecioUnificado
###                                       PrecioUnificado es la uni√≥n de precios en una sola columna

Base <- Base %>%
  mutate(PrecioUnificado = coalesce(price,price.y))

##################################  4.4.  Eliminando columnas que no interesan #
Base <- Base %>%
  dplyr::select(-price.x)

```

###### 4.2. Deflantando Precios a a√±o base 2019

Los precios de las viviendas var√≠an con el paso de los a√±os, aumentan de acuerdo a la inflaci√≥n y a otros aspectos. Para nuestro ejercicio, consideraremos que la inflaci√≥n es la de mayor impacto. Por ende, vamos a deflactar los precios a a√±o base 2019. 

```{r}

################# Creo la columna 'IVPHistorico' y seg√∫n el a√±o le asigno el valor de √≠ndice Valorizaci√≥n Predial (IVP) #
################# Datos de IVP Hist√≥rico tomados de: https://epicainmobiliaria.com/cuanto-valoriza-inmueble-colombia/ #

Base <- Base %>%
  mutate(IVPHistorico = case_when(
    year == 2019 ~ 1,
    year == 2020 ~ 1.091,
    year == 2021 ~ 1.0623,
    TRUE ~ NA_real_  # Para a√±os distintos asigna NA
  ))

################## Creo columna InflacionAcumulada para deflactar precios a a√±o base 2019 #
Base <- Base %>%
  mutate(InflacionAcumulada = case_when(
    year == 2019 ~ 1,
    year == 2020 ~ 1 * 1.091,
    year == 2021 ~ 1.091 * 1.0623,
    TRUE ~ NA_real_
  ))

################## Creo columna de Precios Deflactados llamada PrecioBase #
Base <- Base %>%
  mutate(
    PrecioDeflactado = PrecioUnificado*InflacionAcumulada
  )

```

```{r}

# Dejamos en un solo CRS
upz_bogota <- st_transform(upz_bogota, crs = 4326)
Base <- st_transform(Base, crs = 4326)

# Hacemos un Spatial join: asignar a cada punto la UPZ en la que cae
#    st_within asegura que s√≥lo se unan cuando el punto quede dentro de un pol√≠gono

Base_Bogota <- st_join(
  x = Base,
  y = upz_bogota,
  join = st_within,
  left = TRUE
)

# Eliminamos columnas
Base_Bogota <- Base_Bogota %>%
  dplyr::select(-operation_type,
                -property_type_2,
                -area_matches,
                -area_nums,
                -price.y,
                -price,
                -objectid,
                -zona_estacionamiento,
                -decreto_pot,
                -decreto,
                -shape_area,
                -shape_len,
                -escala_captura,
                -fecha_captura,
                -globalid,
                -responsable
                )
st_write(Base_Bogota, "C:/Users/Juancho/OneDrive/Desktop/MeCA/Big Data y Maching Learning/Taller No. 3/Base_Bogota.geojson", delete_dsn = TRUE)
```



# -----------------------------------------------------------------------------------------------------------------------------
# 5.                                                  Imputando Missing_Values
# ----------------------------------------------------------------------------------------------------------------------------

"surface_covered" sigue siendo la variable con m√°s missing_values, seguido por "surface_total". Teniendo variables como codigo_upz, localidad, distancia a transmilenio, distancia a CAI's, distancia a hospitales, distancia a parques, podemos hacer m√°s especifico una imputaci√≥n. Una metodolog√≠a para imputar missing_values podr√≠a ser la moda o, incluso mejor, la mediana de cada variable. Es decir, emplear un m√©todo de imputaci√≥n univariante. Sin embargo, imputar por estos valores podr√≠a generar un sesgo de informaci√≥n al atribuir un valor est√°ndar que no est√° relacionado a las dem√°s caracter√≠sticas de la vivienda, generando as√≠ predicciones sobreajustadas o subajustadas. Por ello, se piensa en emplear una metodolog√≠a de imputaci√≥n multivariante que tenga en cuenta las dem√°s variables de las viviendas y que haga m√°s precisa la asignaci√≥n de valores faltantes. 

# IMputaci√≥n K- Vecinos m√°s cercanos (KNN)

Es uno de los m√©todos de imputaci√≥n multivariante m√°s eficaces. Funciona encontrando los "vecinos m√°s cercanos" (filas) que presentan patrones similares a la fila con datos faltantes. Estos vecinos se utilizan para calcular los valores faltantes. Esta t√©cnica se basa en el algoritmo KNN , un algoritmo com√∫nmente utilizado en aprendizaje autom√°tico para clasificaci√≥n y regresi√≥n.

En la imputaci√≥n KNN:

- Cada fila se trata como una coordenada en un espacio multidimensional (cada columna representa una dimensi√≥n).
- El algoritmo calcula la distancia entre filas para identificar las m√°s similares.
- Luego, se estima el valor faltante bas√°ndose en los valores de las filas m√°s cercanas.

# Uso de la distancia en la imputaci√≥n KNN

KNN suele utilizar la distancia euclidiana para medir la similitud entre filas. Por ejemplo, en un espacio de cuatro dimensiones:

- Cada fila puede considerarse como un punto en el espacio.
- La distancia entre dos puntos (filas) se calcula utilizando sus coordenadas (valores en columnas).
- Los puntos m√°s cercanos (filas) indican similitud y esas filas se utilizan para estimar el valor faltante.

Hay dos formas principales de calcular la influencia de cada vecino:

- Pesos uniformes : cada vecino tiene una influencia igual.
- Ponderaciones basadas en la distancia : Los vecinos m√°s cercanos tienen mayor influencia. Por ejemplo, un vecino a una distancia de 5 tendr√° mayor impacto que uno a una distancia de 10.

# Ventajas y desventajas de la imputaci√≥n KNN

##Ventajas:

1. Precisi√≥n : KNN a menudo proporciona resultados m√°s precisos que m√©todos m√°s simples como la imputaci√≥n de media o mediana, especialmente para conjuntos de datos complejos.

2. Utiliza m√∫ltiples columnas : dado que KNN considera otras caracter√≠sticas, puede capturar mejor patrones y correlaciones en los datos.

## Desventajas:

1. Computacionalmente costoso : KNN requiere c√°lculos de distancia, que pueden ser lentos para conjuntos de datos grandes.

2. Uso intensivo de memoria : almacena todo el conjunto de entrenamiento para identificar vecinos, lo que puede utilizar mucha memoria.

######                 5.1. Visualizando los missing_values y caracteristicas de las variables
```{r}
skimr::skim(Base_Bogota)
glimpse(Base_Bogota)
```

#####                                           5.2. Conviertiendo a variables tipo factor
```{r}
Base_Bogota$codigo_upz <- as.factor(Base_Bogota$codigo_upz)
Base_Bogota$codigo_localidad <- as.factor(Base_Bogota$codigo_localidad)
                                    
```

######                                      5.3. Funci√≥n de imputaci√≥n por KNN (K-Vecino M√§s Cercano)
```{r}

library(VIM)

# Funci√≥n para imputar missing values por k-Nearest Neighbors
impute_knn <- function(df,
                       vars_objetivo    = c("bathrooms", "bedrooms", "rooms",
                                          "surface_covered", "surface_total"),
                       vars_base = c("bathrooms", "bedrooms", "rooms",
                                          "surface_covered", "surface_total",
                                          "tiene_terraza", "distancia_parque",
                                          "distancia_hospital", "num_restaurantes_700m",
                                          "dist_to_tm", "dist_to_cai", "PrecioDeflactado","codigo_upz"),
                       k = 5) {
  
  # 1. Subconjunto con las variables de inter√©s
  df_imp <- df %>%
    dplyr::select(all_of(unique(c(vars_objetivo, vars_base))))
  
  # 2. Ejecutar kNN de VIM
  #    - variable: las columnas a imputar
  #    - dist_var: variables usadas para calcular distancias
  #    - k: n√∫mero de vecinos
  #    - imp_var = FALSE: no generar columnas indicadores de imputaci√≥n
  imputed_block <- kNN(df_imp,
                       variable = vars_objetivo,
                       dist_var = vars_base,
                       k = k,
                       imp_var = FALSE)
  
  # 3. Reemplazar s√≥lo las columnas imputadas en el df original
  df2 <- df
  df2[vars_objetivo] <- imputed_block[vars_base]
  
  return(df2)
}

```

######                                              5.4. Imputando Missing_values KNN
```{r}

###################################   5.3.1. Imputando miss_values en train_Sf
Base_imputada <- impute_knn(Base_Bogota, k = 5)
```

```{r}
##################################   5.3.2. Revisando los missing_values

skimr::skim(Base_imputada)
glimpse(Base_imputada)
str(Base_imputada)
```

```{r}

##################################   5.3.3. Guardar como archivo GeoJSON

Base_imputada <- Base_imputada %>%
  rename(PrecioValorizado = PrecioDeflactado)

st_write(Base_imputada, "Base_imputada.geojson", delete_dsn = TRUE)
```

```{r}

##################################   5.3.5. Cargando archivo Base_imputada.geojson

Base_imputada <- st_read("C:/Users/Juancho/OneDrive/Desktop/MeCA/Big Data y Maching Learning/Taller No. 3/Base_imputada.geojson", quiet = TRUE)
```

 
# ----------------------------------------------------------------------------------------------------------------------------
#                                                            6. Estad√≠sticas
# ----------------------------------------------------------------------------------------------------------------------------

###                                          6.1. Creamos Columna Precio Metro Cuadrado

```{r}

#################### 6.1.1. Creamos columna preciom2
####################        preciom2 = PrecioDeflactado/surface_covered

Base_imputada <- Base_imputada %>%
  mutate(preciom2 = PrecioValorizado/surface_covered)

skimr::skim(Base_imputada)
```

######                                      6.2. Estad√≠sticas
```{r}

######################################  6.2.1. Frecuencia surface_Total

ggplot(Base_imputada, aes(x = factor(surface_total))) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Superficie Total por Grupo de Observaciones",
       x = "Superficie Total",
       y = "Frecuencia") +
  theme_minimal()

######################################  6.2.2. Frecuencia de ba√±os

ggplot(Base_imputada, aes(x = factor(bathrooms))) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Cantidad de Ba√±os por Grupo de Observaciones",
       x = "N√∫mero de Ba√±os",
       y = "Frecuencia") +
  theme_minimal()

######################################  6.2.3. Frecuencia de surface_covered

ggplot(Base_imputada, aes(x = factor(surface_covered))) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Superficie Cubierta por Grupo de Observaciones",
       x = "Superficie Cubierta",
       y = "Frecuencia") +
  theme_minimal()

######################################  6.2.4. Frecuencia de precio metro cuadrado

ggplot(Base_imputada, aes(x = factor(preciom2))) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Superficie Cubierta por Grupo de Observaciones",
       x = "Precio metro Cuadrado",
       y = "Frecuencia") +
  theme_minimal()

```

```{r}

hist(Base_imputada$PrecioValorizado)
hist(Base_imputada$surface_total)
hist(Base_imputada$surface_covered)
hist(Base_imputada$preciom2)
hist(Base_imputada$bathrooms)

summary(Base_imputada)
```

El argumento skim(), nos permite visualizar que ya no hay valores faltantes en las variables de inter√©s: √°rea cubierta, √°rea total, √°reas comunes, habitaciones y ba√±os. Sin embargo, los valroes faltantes que se observan en la variable terraza se atribuyen principalmente a la extracci√≥n de texto en la columna de "descripcion". Ahora bien, empleando el argumento summary (), podemos observar algunas estad√≠sticas descriptivas de las variables. Inicialmente llama la atenci√≥n los valores de √°rea m√≠nima que hay tanto para surface_covered, como tambi√©n, para surface_total. Se puede atribuir estos valores a errores de digitaci√≥n en las bases de datos o a un error en la extracci√≥n de informaci√≥n en la columna de descripci√≥n. Con respecto a los valores m√°ximos, en el caso de las mismas dos variables, puede considerarse que hay casas o apartamentos cuyo fin son para actividades comerciales. Esta idea se puede complementar con la cantidad de m√°xima de habitaciones, √°reas comunes y ba√±os. En el caso de ba√±os, hay que revisar puntualmente la causa de una observaci√≥n con 2402 ba√±os. Como se ha descrito, muy posiblemente este m√°ximo valor sea por error en la extracci√≥n de datos de la columna de descripci√≥n. 

Al aplicar summary() en la Base_Chapinero, nos damos cuenta que los ba√±os presentan dos valores at√≠picos porque hay valores m√≠nimos de un (1) ba√±o y un m√°ximo de (2402) ba√±os. Para verificar la variabilidad en los valores de ba√±os, primero realizamos una tabla de frecuencia de los n√∫meros de ba√±os, para ello, usamos el argumento ggplot(). La gr√°fica nos permite ver que efectivamente la mediana se concentra en (3) ba√±os pero tambi√©n, que hay valores de (12), (15), (25), (32), (45), (312) Y (2402) ba√±os. Conceptualmente, un ba√±o puede tomar valores continuos cuando no cuenta con ducha (ba√±o a medias). Bajo este argumento, se comprende que los valores de (15), (25), (45) ser√≠an realmente ba√±os sin ducha. Sin embargo, lo valores de (312) y (2402) corresponden a errores en la extracci√≥n de informaci√≥n por la descripci√≥n. Por ende, se deciden eliminar los dos valores. Se transforman los ba√±os con valores de (15), (25), (45) a valores continuos (1,5), (2,5) y (4,5).

El histograma de los precios deflactados refleja una campana asim√©trica positiva donde la mayor cantidad de valores est√°n concentrados en precios bajos y muy pocos valores a precios altos. Mientras que si analizamos el histograma de precio sin deflactar (PrecioUnificado), se puede visualizar que la asimetr√≠a es positiva y una mayor cantidad de viviendas con precios bajos. Para complementar el an√°lisis, se grafica una boxplot.


############                    6.3. Funci√≥n para recodificar bathrooms en un objeto sf ya cargado
```{r}


############################################## 6.3.1. Transformando valores de ba√±os

transform_bathrooms <- function(sf_data) {
  sf_data %>%
    mutate(
      bathrooms = case_when(
        bathrooms == 15 ~ 1,
        bathrooms == 25 ~ 2,
        bathrooms == 35 ~ 3,
        bathrooms == 45 ~ 4,
        TRUE            ~ bathrooms
      )
    )
}


Base_imputada <- Base_imputada %>%
  filter(!is.na(tiene_terraza))

Base_imputada <- transform_bathrooms(Base_imputada)

```

# -----------------------------------------------------------------------------------------------------------------------------
# 7. Eliminando Outliers Bogot√° D.C. 
# -----------------------------------------------------------------------------------------------------------------------------

###                     7.2. FUnci√≥n Elimina Outliers (surface_covered, surface_total y precioValorizado)
```{r}
# Funci√≥n para eliminar outliers en m√∫ltiples variables

remove_outliers <- function(data, 
                            vars = c("surface_total", "surface_covered", "PrecioValorizado", "bathrooms", "preciom2"), 
                            k = 1.5) {
  
  df <- data
  
  for (v in vars) {
    # Calcula cuartiles y rango intercuart√≠lico
    q <- quantile(df[[v]], probs = c(0.25, 0.75), na.rm = TRUE)
    iqr <- diff(q)
    
    lower <- q[1] - k * iqr
    upper <- q[2] + k * iqr
    
    # Filtra filas dentro de los l√≠mites
    df <- df %>%
      filter(between(.data[[v]], lower, upper))
  }
  
  return(df)
}

#################################################### Aplicamos la funci√≥n

Base_limpia <- remove_outliers(Base_imputada)


```

###                                      7.3. Grafican Outliers antes y despu√©s de funci√≥n
### 7.3.1. BoxPlot Ba√±os
```{r}


# 1. Seleccionar y pivotar los datos para comparaci√≥n
BoxPlo_Ba√±os <- list(
  antes  = Base_imputada %>%
    st_drop_geometry() %>%
    dplyr::select(bathrooms),
  despues = Base_limpia  %>% 
    st_drop_geometry() %>%
    dplyr::select(bathrooms)
) %>%
  bind_rows(.id = "set") %>%
  pivot_longer(
    cols = -set,
    names_to  = "variable",
    values_to = "valor"
  )

# 2. Graficar los boxplots comparativos
ggplot(BoxPlo_Ba√±os, aes(x = variable, y = valor, fill = set)) +
  geom_boxplot(position = position_dodge(width = 0.8), outlier.shape = 1) +
  labs(
    title    = "Boxplots_Ba√±os antes vs. despu√©s de remover outliers",
    x        = "Variable",
    y        = "Valor",
    fill     = "Conjunto"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### 7.3.2. BoxPlot Superficie Cubierta
```{r}


# 1. Seleccionar y pivotar los datos para comparaci√≥n
BoxPlo_SurfaceCovered <- list(
  antes  = Base_imputada %>%
    st_drop_geometry() %>%
    dplyr::select(surface_covered),
  despues = Base_limpia  %>% 
    st_drop_geometry() %>%
    dplyr::select(surface_covered)
) %>%
  bind_rows(.id = "set") %>%
  pivot_longer(
    cols = -set,
    names_to  = "variable",
    values_to = "valor"
  )

# 2. Graficar los boxplots comparativos
ggplot(BoxPlo_SurfaceCovered, aes(x = variable, y = valor, fill = set)) +
  geom_boxplot(position = position_dodge(width = 0.8), outlier.shape = 1) +
  labs(
    title    = "Boxplots Superficies Cubiertas antes vs. despu√©s de remover outliers",
    x        = "Variable",
    y        = "Valor",
    fill     = "Conjunto"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### 7.3.3. BoxPlot Superficie Total
```{r}


# 1. Seleccionar y pivotar los datos para comparaci√≥n
BoxPlo_Total <- list(
  antes  = Base_imputada %>%
    st_drop_geometry() %>%
    dplyr::select(surface_total),
  despues = Base_limpia  %>% 
    st_drop_geometry() %>%
    dplyr::select(surface_total)
) %>%
  bind_rows(.id = "set") %>%
  pivot_longer(
    cols = -set,
    names_to  = "variable",
    values_to = "valor"
  )

# 2. Graficar los boxplots comparativos
ggplot(BoxPlo_Total, aes(x = variable, y = valor, fill = set)) +
  geom_boxplot(position = position_dodge(width = 0.8), outlier.shape = 1) +
  labs(
    title    = "Boxplots Superficies Totales antes vs. despu√©s de remover outliers",
    x        = "Variable",
    y        = "Valor",
    fill     = "Conjunto"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### 7.3.4. BoxPlot Precio Valorizado
```{r}


# 1. Seleccionar y pivotar los datos para comparaci√≥n
BoxPlo_PrecioValorizado <- list(
  antes  = Base_imputada %>%
    st_drop_geometry() %>%
    dplyr::select(PrecioValorizado),
  despues = Base_limpia  %>% 
    st_drop_geometry() %>%
    dplyr::select(PrecioValorizado)
) %>%
  bind_rows(.id = "set") %>%
  pivot_longer(
    cols = -set,
    names_to  = "variable",
    values_to = "valor"
  )

# 2. Graficar los boxplots comparativos
ggplot(BoxPlo_PrecioValorizado, aes(x = variable, y = valor, fill = set)) +
  geom_boxplot(position = position_dodge(width = 0.8), outlier.shape = 1) +
  labs(
    title    = "Boxplots Precios Valorizados antes vs. despu√©s de remover outliers",
    x        = "Variable",
    y        = "Valor",
    fill     = "Conjunto"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### 7.3.5. BoxPlot Precio metro Cuadrado
```{r}


# 1. Seleccionar y pivotar los datos para comparaci√≥n
BoxPlo_PrecioM2 <- list(
  antes  = Base_imputada %>%
    st_drop_geometry() %>%
    dplyr::select(preciom2),
  despues = Base_limpia  %>% 
    st_drop_geometry() %>%
    dplyr::select(preciom2)
) %>%
  bind_rows(.id = "set") %>%
  pivot_longer(
    cols = -set,
    names_to  = "variable",
    values_to = "valor"
  )

# 2. Graficar los boxplots comparativos
ggplot(BoxPlo_PrecioM2, aes(x = variable, y = valor, fill = set)) +
  geom_boxplot(position = position_dodge(width = 0.8), outlier.shape = 1) +
  labs(
    title    = "Boxplots Precio Metro Cuadrado antes vs. despu√©s de remover outliers",
    x        = "Variable",
    y        = "Valor",
    fill     = "Conjunto"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

```{r}
hist(Base_limpia$PrecioValorizado)
hist(Base_limpia$surface_total)
hist(Base_limpia$surface_covered)
hist(Base_limpia$preciom2)
hist(Base_limpia$bathrooms)
```

```{r }
summary(Base_limpia)
```

# ----------------------------------------------------------------------------------------------------------------------------
#                                                           8. Distribuci√≥n Espacial
# ----------------------------------------------------------------------------------------------------------------------------

#                                       8.1. Distribuci√≥n Espacial Precio Valorizado Promedio por UPZ
```{r}

# Distribuci√≥n Espacial de Precio Valorizado promedio por UPZ #

UPZ_PrecioValorizado <- Base_limpia %>%
  st_drop_geometry() %>%
  group_by(nombre) %>%
  summarise(precio_promedio = mean(PrecioValorizado, na.rm = TRUE),
            n = n())

## Unir con las geometr√≠as ##
Geo_UPZPrecioValorizado <- left_join(upz_bogota, UPZ_PrecioValorizado, by = "nombre")

## Usar este objeto con geometr√≠as en leaflet ##
leaflet(Geo_UPZPrecioValorizado) %>%
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(
    fillColor = ~colorQuantile("YlOrRd", precio_promedio)(precio_promedio),
    color = "#444444", weight = 1, fillOpacity = 0.8,
    popup = ~paste("Barrio:", nombre, "<br>Precio promedio: $", round(precio_promedio, 0))
  )

```

# #                                       8.2. Distribuci√≥n Espacial Completo
```{r}

# Tu c√≥digo original
UPZ_Completo <- Base_limpia %>%
  st_drop_geometry() %>%
  group_by(nombre, property_type) %>%
  summarise(precio_promedio = mean(PrecioValorizado, na.rm = TRUE),
            surface_covered_prom = mean(surface_covered, na.rm = TRUE),
            preciom2_prom = mean(preciom2, na.rm = TRUE),
            n = n())

# Unir con las geometr√≠as
Geo_Completo <- left_join(upz_bogota, UPZ_Completo, by = "nombre")

# Filtrar solo para Casa y Apartamento
Geo_Casa_Apartamento <- Geo_Completo %>%
  filter(property_type %in% c("Casa", "Apartamento")) %>%
  filter(!is.na(precio_promedio))

# Crear paleta de colores para el precio promedio
pal_precio <- colorNumeric(
  palette = "Spectral",
  domain = Geo_Casa_Apartamento$precio_promedio,
  na.color = "transparent",
  reverse = TRUE
)

# Crear paleta de colores espec√≠fica para Casa y Apartamento
colores_property <- c("Casa" = "#FF6B6B", 
                     "Apartamento" = "#4ECDC4")

pal_property <- colorFactor(
  palette = colores_property,
  domain = c("Casa", "Apartamento")
)

# Crear etiquetas emergentes (popups) m√°s detalladas
labels <- sprintf(
  "<div style='font-size: 14px;'>
   <strong style='color: #2E86AB; font-size: 16px;'>%s</strong><br/>
   <strong style='color: %s;'>üè† %s</strong><br/>
   <hr style='margin: 5px 0;'>
   üí∞ <strong>Precio Promedio:</strong> $%s<br/>
   üìê <strong>Superficie Promedio:</strong> %.1f m¬≤<br/>
   üíµ <strong>Precio por m¬≤:</strong> $%s<br/>
   üìä <strong>Propiedades:</strong> %d
   </div>",
  Geo_Casa_Apartamento$nombre,
  ifelse(Geo_Casa_Apartamento$property_type == "Casa", "#FF6B6B", "#4ECDC4"),
  Geo_Casa_Apartamento$property_type,
  format(round(Geo_Casa_Apartamento$precio_promedio, 0), big.mark = ",", scientific = FALSE),
  round(Geo_Casa_Apartamento$surface_covered_prom, 1),
  format(round(Geo_Casa_Apartamento$preciom2_prom, 0), big.mark = ",", scientific = FALSE),
  Geo_Casa_Apartamento$n
) %>% lapply(htmltools::HTML)

# Separar datos por tipo de propiedad para capas independientes
Geo_Casas <- Geo_Casa_Apartamento %>% filter(property_type == "Casa")
Geo_Apartamentos <- Geo_Casa_Apartamento %>% filter(property_type == "Apartamento")

# Crear el mapa interactivo
mapa_casa_apartamento <- leaflet() %>%
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles(providers$CartoDB.Positron, group = "CartoDB") %>%
  
  # Capa de Casas coloreada por precio
  addPolygons(
    data = Geo_Casas,
    fillColor = ~pal_precio(precio_promedio),
    weight = 2,
    opacity = 1,
    color = "#FF6B6B",
    dashArray = "3",
    fillOpacity = 0.7,
    highlight = highlightOptions(
      weight = 4,
      color = "#FF6B6B",
      dashArray = "",
      fillOpacity = 0.9,
      bringToFront = TRUE
    ),
    popup = labels[Geo_Casa_Apartamento$property_type == "Casa"],
    group = "üè† Casas"
  ) %>%
  
  # Capa de Apartamentos coloreada por precio
  addPolygons(
    data = Geo_Apartamentos,
    fillColor = ~pal_precio(precio_promedio),
    weight = 2,
    opacity = 1,
    color = "#4ECDC4",
    dashArray = "3",
    fillOpacity = 0.7,
    highlight = highlightOptions(
      weight = 4,
      color = "#4ECDC4",
      dashArray = "",
      fillOpacity = 0.9,
      bringToFront = TRUE
    ),
    popup = labels[Geo_Casa_Apartamento$property_type == "Apartamento"],
    group = "üè¢ Apartamentos"
  ) %>%
  
  # Capa combinada coloreada por tipo de propiedad
  addPolygons(
    data = Geo_Casa_Apartamento,
    fillColor = ~pal_property(property_type),
    weight = 1.5,
    opacity = 1,
    color = "white",
    dashArray = "2",
    fillOpacity = 0.8,
    highlight = highlightOptions(
      weight = 3,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.9,
      bringToFront = TRUE
    ),
    popup = labels,
    group = "üè†üè¢ Comparaci√≥n"
  ) %>%
  
  # Agregar leyenda para precios
  addLegend(
    pal = pal_precio, 
    values = Geo_Casa_Apartamento$precio_promedio,
    opacity = 0.8, 
    title = htmltools::HTML("Precio Promedio<br/>(Millones COP)"),
    position = "bottomright",
    group = "Leyenda Precio"
  ) %>%
  
  # Agregar leyenda para tipos de propiedad
  addLegend(
    colors = c("#FF6B6B", "#4ECDC4"),
    labels = c("üè† Casa", "üè¢ Apartamento"),
    opacity = 0.8,
    title = "Tipo de Propiedad",
    position = "bottomleft"
  ) %>%
  
  # Control de capas
  addLayersControl(
    baseGroups = c("OpenStreetMap", "CartoDB"),
    overlayGroups = c("üè† Casas", "üè¢ Apartamentos", "üè†üè¢ Comparaci√≥n"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>%
  
  # Configurar vista inicial en Bogot√°
  setView(lng = -74.08, lat = 4.60, zoom = 11) %>%
  
  # Ocultar inicialmente las capas individuales
  hideGroup(c("üè†üè¢ Comparaci√≥n"))

# Mostrar el mapa
mapa_casa_apartamento

```

#                                               8.3. Graficando por tipo de propiedad en Bogot√°
```{r}

Base_limpia %>%
  st_drop_geometry() %>%
  group_by(property_type) %>%
  summarise(PrecioValorizado_prom = mean(PrecioValorizado, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(property_type, -PrecioValorizado_prom), y = PrecioValorizado_prom)) +
  geom_bar(stat = "identity", fill = "darkgreen", alpha = 0.7) +
  geom_text(aes(label = scales::comma(round(PrecioValorizado_prom, 0))),
            vjust = 1.5, color = "white", size = 4) +  # Texto dentro de la barra
  labs(title = "Precio Valorizado Promedio por Tipo de Propiedad en Bogot√°",
       x = "Tipo de Propiedad", y = "Precio Valorizado Promedio") +
  scale_y_continuous(labels = scales::comma) +
  theme_minimal()
```


#                                                        8.4.  Matriz de Correlaciones
```{r}

variables <- Base_limpia %>%
  st_drop_geometry() %>%
  dplyr::select(PrecioValorizado, bathrooms, bedrooms, rooms, surface_total, surface_covered, preciom2, tiene_terraza, distancia_parque, distancia_hospital, num_restaurantes_700m, dist_to_tm, dist_to_cai)

# Calcular matriz de correlaci√≥n
matriz_CorrLimpia <- cor(variables, use = "complete.obs")

# Visualizar correlaci√≥n con ggcorrplot
ggcorrplot(matriz_CorrLimpia, 
           hc.order = TRUE, 
           type = "lower",
           lab = TRUE, 
           colors = c("blue", "white", "red"),
           title = "Matriz de Correlaci√≥n Chapinero")

# Visualizar la matriz de correlaci√≥n
corrplot(matriz_CorrLimpia, 
         method = "color",       # Tipo de visualizaci√≥n
         col = colorRampPalette(c("blue", "white", "red"))(200),
         type = "upper",         # Solo tri√°ngulo superior
         tl.col = "black",       # Color de etiquetas
         tl.cex = 0.9,           # Tama√±o de texto
         number.cex = 0.7,       # Tama√±o de n√∫meros
         addCoef.col = "black")  # A√±adir valores num√©ricos


# Tercera opci√≥n para visualizar matriz de correlaci√≥n
heatmap(matriz_CorrLimpia, 
        main = "Mapa de Calor - Matriz de Correlaci√≥n",
        col = colorRampPalette(c("blue", "white", "red"))(100), 
        scale = "none")
```



# ----------------------------------------------------------------------------------------------------------------------------
#                                                   9. CARLOS
# ----------------------------------------------------------------------------------------------------------------------------


#                                           9.1. Seleccionar Variables

```{r}
library(keras)

db <- Base_limpia %>% 
  dplyr::select(property_type,dist_to_tm,num_restaurantes_700m,near_cai,tiene_terraza,surface_covered, bathrooms, bedrooms, rooms, PrecioValorizado, distancia_parque, distancia_hospital, dist_to_cai, origen, nombre, codigo_upz, codigo_localidad)
```

#                                9.2. test (Chapinero) y train (Diferente a Chapinero)
```{r}

# Seleccionamos las UPZ que son similares en Precio Valorizado

db <- db %>% 
  filter(nombre == "CHAPINERO",
         nombre == "CHICO LAGO",
         nombre == "PARDO RUBIO",
         nombre == "EL REFUGIO",
         nombre == "TEUSAQUILLO",
         nombre == "CIUDAD SALITRE ORIENTAL",
         nombre == "MODELIA",
         nombre == "CIUDAD SALITRE OCCIDENTAL",
         nombre == "JARDIN BOTANICO",
         nombre == "SANTA BARBARA",
         nombre == "COUNTRY CLUB",
         nombre == "USAQUEN",
         nombre == "LOS ANDES",
         nombre == "LOS ALCAZARES"
  )

# Definimos test

val_set <- db %>%
  filter(origen == "test")


# Definimos train

train <- db %>%
  filter(origen == "train")

```

#                                               9.3. PREPROSSES DATA FOR KERAS
```{r}

str(train)

###                                                    Para train

train <- train %>%
  mutate(tiene_terraza = ifelse(is.na(tiene_terraza), 
                                0,  
                                tiene_terraza))

train <- train %>% 
  st_drop_geometry() %>%
  dplyr::select(-codigo_localidad,
                -origen,              # para evitar tener problemas con caret son de tipo <chr>
                -nombre,
                -property_type,
                -codigo_upz
  )

dmy <- caret::dummyVars(
  ~ .,
  data = train,
  sep = "_", # Separador para las variables dummy
  drop = TRUE,
  fullRank = TRUE # Evitar la multicolinealidad
)

train <- as.data.frame(predict(dmy, newdata = train))

X_train <- train %>% dplyr::select(-PrecioValorizado)
y_train <- train$PrecioValorizado

X_train <- as.matrix(train %>% dplyr::select(-PrecioValorizado))
y_train <- as.matrix(train$PrecioValorizado)

###                                                Para test

val_set <- val_set %>% 
  st_drop_geometry() %>%
  dplyr::select(-codigo_localidad,
                -origen,              # para evitar tener problemas con caret son de tipo <chr>
                -nombre,
                -property_type,
                -codigo_upz
  )

dmy2 <- caret::dummyVars(
  ~ .,
  data = val_set,
  sep = "_", # Separador para las variables dummy
  drop = TRUE,
  fullRank = TRUE # Evitar la multicolinealidad
)

val_set <- as.data.frame(predict(dmy2, newdata = val_set))

X_test <- as.matrix(val_set %>% dplyr::select(-PrecioValorizado))
y_test <- as.matrix(val_set$PrecioValorizado)
```

#                                              9.4. Keras Model Definition Function
```{r}

```










```{r}

```

```{r}

```

```{}

```

```{r}

```

```{r}

```

```{}

```


```{r}

```

```{r}

```

```{}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```


```{r}

```

```{r}

```

```{}

```

```{r}

```

```{r}

```

```{}

```


```{r}

```

```{r}

```

```{}

```
